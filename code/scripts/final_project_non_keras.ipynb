{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564bit8ef63aba3f24491db99035316b265dfd",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['What is the Turing Test?', 'The original Turing test involved three entities communicating with each other through computer terminals in separate rooms - a computer program trying to pass itself off as a human, a human trying to prove that she or he is human, and a human judge deciding which of the competitors is human and which a machine. This is different from the popular idea that it\\'s about a human judging whether one subject is human or machine. The reason it\\'s different is that Turing\\'s original proposal was not intended as a practical test, but rather as a thought experiment making a philosophical argument - that it is impossible to determine whether something is \"intelligent\" better than by judging its linguistic interactions, and that therefore a machine that sounds intelligent has to be considered truly intelligent. And by \"intelligent,\" Turing meant, like a human, with consciousness.', 'Which of the following is NOT an objection to the Turing Test mentioned in the reading?', 'Intelligence is not the same thing as consciousness.', 'Many human beings might not pass the Turing test.|||Language is not necessarily the only way to demonstrate high intelligence.|||Cognitive ability is cognitive ability whether demonstrated through behavior or not.', 'The Turing Test web page||document||N/A|||The Turing test paragraph from Stanford Encyclopedia of Philosophy||image||N/A']\n \n['Turing test', 'Alan Turing', 'Computational linguistics', 'Language philosophy', 'Artificial Intelligence', 'Philosophy of artificial intelligence']\n"
    }
   ],
   "source": [
    "data = [i.strip('\\n').split('\\t') for i in open('/Users/Diego/Documents/School/ISTA539/final-project-dalcantara7/openclass_prize.train', 'r', encoding='utf8', errors='ignore')]\n",
    "print(data[0])\n",
    "print(\" \")\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['What is the Turing Test? The original Turing test involved three entities communicating with each other through computer terminals in separate rooms - a computer program trying to pass itself off as a human, a human trying to prove that she or he is human, and a human judge deciding which of the competitors is human and which a machine. This is different from the popular idea that it\\'s about a human judging whether one subject is human or machine. The reason it\\'s different is that Turing\\'s original proposal was not intended as a practical test, but rather as a thought experiment making a philosophical argument - that it is impossible to determine whether something is \"intelligent\" better than by judging its linguistic interactions, and that therefore a machine that sounds intelligent has to be considered truly intelligent. And by \"intelligent,\" Turing meant, like a human, with consciousness. Which of the following is NOT an objection to the Turing Test mentioned in the reading? Intelligence is not the same thing as consciousness. Many human beings might not pass the Turing test.|||Language is not necessarily the only way to demonstrate high intelligence.|||Cognitive ability is cognitive ability whether demonstrated through behavior or not. The Turing Test web page||document||N/A|||The Turing test paragraph from Stanford Encyclopedia of Philosophy||image||N/A', 'What is inflectional morphology? Inflectional morphology is when we have a change in word form, for example \"perform\" and \"performed.\" What is the difference between inflectional and derivational morphology? Derivational morphology is where we have a new word. One is part of micro- and the other is part of macro-linguistics.|||Inflectional morphology means the suffix changes.|||Derivational morphology is where morphemes are derived from phonemes. Inflection in Morphology presentation||slides||Inflection Bayu Jaka Magistra 180120130006 Indah  Mustika S. M . 180120130003  Inflection  Inflection  What is Inflection ?  Regular  & Irregular  Inflection  Forms of Nouns   Forms of Pronouns  & Determiners  Forms of Verbs  Forms of Adjectives   `   What is Inflection ?  What is Inflection?  1. The pianist performs in the local café  every month. 2. The pianist performed in the local café last night.  3. The performance was extraordinary.  What is Inflection? 1. The pianist performs in the local café  every month. 2. The pianist performed in the local café last night.  3. The performance was extraordinary.  What is Inflection? 1. The pianist  performs in the local café  every month. 2. The pianist  performed in the local café last night.  3. The  performance was extraordinary.  The words performs, performed & performance belong to the same root which is perform .  However, the word performs & performed in sentence ( 1 ) & ( 2 ) belong to the same word class i . e . verb .  The word Performance in sentence ( 3 ) , on the other hand, belongs to the different word class i . e . noun .  What is Inflection? 1. The pianist  performs in the local café  every month. 2. The pianist  performed in the local café last night.   What happens in sentence ( 1 ) and ( 2 ) is the process of word formation called inflection .  Inflection does not change the word class (parts of speech) and meaning of a word  Instead, Inflection is grammatically conditioned (McCarthy, 2002 ), or expresses grammatical categories like tense, mood, voice, aspect, person, number, gender and case . 1 1  Inflection . (2013, September 12).  Retrieved November 24, 2013,  from www.wikipedia.org : http://en.wikipedia.org/wiki/Inflection  What is Inflection? 1. The pianist  performs in the local café  every month. 2. The pianist  performed in the local café last night.  Grammatically condition or expresses grammatical categories like  tense, mood, voice, aspect, person, number, gender and case.  In sentence ( 1 ) the suffix - s is added to the root because of being grammatically conditioned by third - person singular subject the pianist .  In sentence ( 2 ) the suffix - ed is added to the root to express past tense .  What is Inflection? 3. The  performance was extraordinary.  What happens in sentence ( 3 ), on the other hand, is the process of word formation called derivation .  Derivation is the process of  new words by adding affixes to existing words .  ( Trask , 2007 ) .  Derivation changes the word class and/or meaning of the root .  What is Inflection? ROOT  Word class  Meaning Inflection Variants Variants Variants  What is Inflection? PERFORM  Verb  To execute Inflection Perform s Perform ing Perform ed  The variants still  belong to the  same word class  (verb), and have  the same  meaning  However, they are  grammatically  conditioned, or  express certain  grammatical  category grammatically  conditioned by third - person singular  subject Expressing continuous  and progressive  aspects Expressing past tense  What is Inflection? PERFORM  Verb  To execute Perform ance  Noun  The act of  performing Perform er  Noun  One who  performs Inflection Inflection Perform ance s Plural Perform er s Plural  Regular & Irregular Inflection Cats Guitars Hats Tables  Chairs Doors Windows  Regular & Irregular Inflection Cat s Guitar s Hat s Table s Chair s Door s Window s  Regular & Irregular Inflection Cat s Guitar s Hat s Table s Chair s Door s Window s  Adding suffix - s to a noun root is the regular method of forming plural .  Regular & Irregular Inflection Mice Children Women Teeth Oxen Men Knives are irregular plural forms of  Mouse Child Woman Tooth Ox Man Knife are allomorphs of   Regular & Irregular Inflection Went Better Worse are irregular inflection forms of  Go Good Bad Allomorphs ???  Regular & Irregular Inflection Went Better Worse Suppletion of  Go Good Bad Suppletion  Regular & Irregular Inflection Suppletion vs. Allomorph Allomorph Mice Children Women Teeth Oxen Men Knives Root Mouse Child Woman Tooth Ox Man Knife  Regular & Irregular Inflection Suppletion vs. Allomorph Allomorph M i ce Child ren Wom e n T ee th Ox en M e n Kni ves Root M ou se Child Wom a n T oo th Ox M a n Kni fe An allomorph has similar  phoneme(s) as its root  Regular & Irregular Inflection Suppletion vs. Allomorph Root Went Better Worse Suppletion Go Good Bad Suppletion and its root  does not have any similar  phoneme.  Forms of Nouns  Inflection in nouns expresses  grammatical category which is number.  Regular forms (adding the suffix  - s)  Irregular forms (Allophones, zero suffix  like  deer, fish, sheep )   4.4 Forms of Pronouns And  Determiners Open classes :  Nouns, Adjectives, Verbs,   Adverbs Determiners:  nouns , display a singular - plural  contrast  P ro - nouns  combine a singular - plural contrast  with contrast unique to them, between  subject and non - subject forms.   T he  distinction between this and  these.  These  are the singular and plural forms of the  determinest lexeme  this.  The  determiners THAT and THIS demonstrate  that number contrasts can have a grammatical  effect inside noun phrase as well as between  subject noun phrases and their accompanying  verbs.   In English, the same technique is used for one  small closed class of lexemes, namely personal  pronouns.  If  one replaces John and Mary with the  appropriate pronouns in these two examples,  the outcome is as in: 1. He  loves her. 2. She  loves him.   He and him are sometimes said to contrast in  case. 1. He belonging to the nominative  case 2. H im belonging to the accusative case .  It  is striking that the relationship between  nominative and accusative forms is  consistently  suppletive . >>  I/me, she/her, we/us, and they/them.    Corresponding words with a possessive  meaning: his and our, as well as my, her, your  and their.  Syntactically and semantically, these words  fulfill just the same role as noun phrases with  the apostrophe - s: 1.  His bicycle  means the bicycle belonging   to him. 2.   bicycle means the bicycle  belonging to that man.  4.5 Forms of  Verbs  In English, a verb lexeme has at most five distinct  forms, as illustrated here with GIVE .  Third person singular present tense e.g . Marry  gives a lecture every year.  Past tense e.g . Marry  gave a lecture last week.  Progressive participle e.g . Mary is  giving a lecture today.  Perfect or passive participle e.g . Mary has  given a lecture today.  Basic form (used everywhere else) e.g Mary wants to  give a lecture.  4.6  Forms of  Adjectives  Many  English adjectives exhibit three forms,  for example GREEN here: 1. Grass  is  green . 2. The  grass is  greener now than in winter. 3. The  grass is  greenest in early summer.  Other adjectives with  similar forms: Positive Comprative Superlative Happy happier happiest Long longer longest Pure purer purest Untidy untidier untidiest Good better best All  these exhibit a regular pattern of suffixation with   er and   est , except for better and best, which are  suppletive .', 'What English sentence could represent the following set of first order logic expressions? The answer is “What game do you want to play with me today?” Which of the following expressions could belong in an FOL representation of, â\\x80\\x9cWhat do you want to play with?â\\x80\\x9d with(play, $qvar) play(want, $qvar)|||want(play, $qvar)|||play(with, $qvar) NONE']\n \n[['Turing test', 'Alan Turing', 'Computational linguistics', 'Language philosophy', 'Artificial Intelligence', 'Philosophy of artificial intelligence'], ['Inflectional morphology', 'Inflection', 'Derivational morphology', 'Morphology', 'Macrolinguistics'], ['First-order logic', 'Predicate logic', 'Semantics', 'Sentence analysis'], ['Logistic regression', 'Text classification', 'Binary classification', 'Natural Language Processing (NLP)'], ['Naive Bayes', 'Text classification', 'Binary Naive Bayes (NB)', 'Sentiment analysis']]\n"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(len(data)):\n",
    "    if i % 2 == 0:\n",
    "        X.append(' '.join(data[i]))\n",
    "    else:\n",
    "        Y.append(data[i])\n",
    "\n",
    "print(X[0:3])\n",
    "print(\" \")\n",
    "print(Y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#may not need any of this with the glove embedding I am using\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "\n",
    "def clean_data(dataset):\n",
    "    clean_data = []\n",
    "    sno = SnowballStemmer('english')\n",
    "\n",
    "    for entry in dataset:\n",
    "        lowered = entry.lower()\n",
    "        sans_special_chars = re.sub(r'\\W',' ', lowered)\n",
    "        sans_extra_spaces = re.sub(r'\\s+',' ', sans_special_chars)\n",
    "        sans_underscore = sans_extra_spaces.replace('_', ' ')\n",
    "        split = sans_underscore.split()\n",
    "        stemmed = ' '.join([sno.stem(word) for word in split])\n",
    "        clean_data.append(stemmed)\n",
    "\n",
    "    return clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_X = clean_data(X)\n",
    "# print(clean_X[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Turing test', 'Alan Turing', 'Computational linguistics', 'Language philosophy', 'Artificial Intelligence']\n"
    }
   ],
   "source": [
    "labels = [item for sublist in Y for item in sublist]\n",
    "print(labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "716\n"
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_labels = np.zeros((len(Y), len(labels)))\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    for j in range(len(Y[i])):\n",
    "        for k in range(len(labels)):\n",
    "            if Y[i][j] == labels[k]:\n",
    "                sample_labels[i][k] = 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Length of X:  163\nLength of Y:  163\nLength of X_train:  130\nLength of Y_train:  130\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, sample_labels, test_size=0.2)\n",
    "print(\"Length of X: \", len(X))\n",
    "print(\"Length of Y: \", len(Y))\n",
    "print(\"Length of X_train: \", len(X_train))\n",
    "print(\"Length of Y_train: \", len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nTrain Data:  [[346   7  19 ...   0   0   0]\n [ 55   7   4 ...   0   0   0]\n [471   1 174 ...   0   0   0]]\nTest Data:  [[  85  114 8917 ...    0    0    0]\n [  55   52  683 ...    0    0    0]\n [ 803    4    7 ...    0    0    0]]\n"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import keras.preprocessing.sequence as kps\n",
    "NUM_WORDS = 120000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "train_indices = tokenizer.texts_to_sequences(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "train_indices = kps.pad_sequences(train_indices, padding='post')\n",
    "\n",
    "test_indices = tokenizer.texts_to_sequences(X_test)\n",
    "test_indices = kps.pad_sequences(test_indices, padding='post', maxlen=len(train_indices[0]))\n",
    "\n",
    "print(\"Train Data: \", train_indices[0:3])\n",
    "print(\"Test Data: \", test_indices[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "e-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 591 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 592 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 593 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 595 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 596 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 597 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 599 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 600 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 601 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 602 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 603 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 604 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 606 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 607 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 609 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 610 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 611 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 612 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 614 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 616 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 617 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 618 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 619 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 620 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 621 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 622 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 623 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 624 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 626 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 627 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 628 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 629 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 630 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 631 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 632 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 633 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 634 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 635 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 636 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 637 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 638 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 639 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 640 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 641 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 642 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 643 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 644 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 645 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 646 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 647 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 648 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 649 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 650 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 651 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 652 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 653 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 654 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 655 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 656 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 657 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 659 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 660 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 661 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 664 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 665 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 666 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 667 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 668 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 669 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 670 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 673 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 674 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 675 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 676 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 677 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 679 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 680 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 681 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 682 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 683 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 684 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 685 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 686 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 688 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 689 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 690 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 691 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 693 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 694 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 698 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 699 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 702 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 703 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 706 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 707 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 708 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 709 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 710 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 711 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 712 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 713 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 714 is present in all training examples.\n  str(classes[c]))\n/usr/local/lib/python3.7/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 715 is present in all training examples.\n  str(classes[c]))\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf = OneVsRestClassifier(LogisticRegression(solver='saga', class_weight={0 : 1, 1 : 150}, max_iter=50)).fit(train_indices, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prob = clf.predict_proba(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "predictions = np.where(predictions_prob > 0.7, 1, 0)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.0009317748142408658\n0.03918495297805643\n0.01192634895698725\n"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, _, __ = precision_recall_fscore_support(Y_test, predictions, average='macro')\n",
    "print((5 *  precision * recall) / (4 * (precision+recall)))\n",
    "precision, recall, _, __ = precision_recall_fscore_support(Y_test, predictions, average='micro')\n",
    "print((5 *  precision * recall) / (4 * (precision+recall)))\n",
    "precision, recall, _, __ = precision_recall_fscore_support(Y_test, predictions, average='weighted')\n",
    "print((5 *  precision * recall) / (4 * (precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}